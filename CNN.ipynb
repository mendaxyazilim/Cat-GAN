{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from random import randrange\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_data():\n",
    "\tprint('Reading image data ...')\n",
    "\ttrain_x = np.load('../../Data/data_train.npy')\n",
    "\ttrain_y = np.load('../../Data/train_labels.npy')\n",
    "\ttest_x = np.load('../../Data/data_test.npy')\n",
    "\n",
    "\treturn (train_x, train_y, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading image data ...\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x = read_image_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(len(train_x), 32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = []\n",
    "for x in range(len(train_y)):\n",
    "    if(train_y[x] == 0):\n",
    "        onehot.append([1,0,0,0])\n",
    "    elif(train_y[x] == 1):\n",
    "        onehot.append([0,1,0,0])\n",
    "    elif(train_y[x] == 2):\n",
    "        onehot.append([0,0,1,0])\n",
    "    else:\n",
    "        onehot.append([0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 4)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot = np.array(onehot)\n",
    "onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(train_x, onehot, test_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the checkpoint :\n",
    "checkpoint = EarlyStopping(monitor='loss', min_delta=0.00001, patience=15, verbose=1, mode='auto', restore_best_weights=True)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_64 (Conv2D)           (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 32, 32, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 1,133,348\n",
      "Trainable params: 1,133,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (32,32,3)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation = \"softmax\"))\n",
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 1.3948 - accuracy: 0.3223\n",
      "Epoch 2/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 1.1783 - accuracy: 0.4927\n",
      "Epoch 3/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 1.0204 - accuracy: 0.5677\n",
      "Epoch 4/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.9304 - accuracy: 0.6093\n",
      "Epoch 5/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.8564 - accuracy: 0.6534\n",
      "Epoch 6/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.7782 - accuracy: 0.6901\n",
      "Epoch 7/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.7277 - accuracy: 0.7131\n",
      "Epoch 8/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.6728 - accuracy: 0.7337\n",
      "Epoch 9/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.6215 - accuracy: 0.7569\n",
      "Epoch 10/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.5850 - accuracy: 0.7736\n",
      "Epoch 11/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.5466 - accuracy: 0.7893\n",
      "Epoch 12/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.4868 - accuracy: 0.8141\n",
      "Epoch 13/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.4710 - accuracy: 0.8201\n",
      "Epoch 14/2500\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.4324 - accuracy: 0.8373\n",
      "Epoch 15/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.3967 - accuracy: 0.8501\n",
      "Epoch 16/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.3747 - accuracy: 0.8584\n",
      "Epoch 17/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.3531 - accuracy: 0.8662\n",
      "Epoch 18/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.3337 - accuracy: 0.8733\n",
      "Epoch 19/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.3046 - accuracy: 0.8877\n",
      "Epoch 20/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.2900 - accuracy: 0.8931\n",
      "Epoch 21/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.2601 - accuracy: 0.9054\n",
      "Epoch 22/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.2534 - accuracy: 0.9075\n",
      "Epoch 23/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.2440 - accuracy: 0.9101\n",
      "Epoch 24/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.2216 - accuracy: 0.9193\n",
      "Epoch 25/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.2192 - accuracy: 0.9203\n",
      "Epoch 26/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1979 - accuracy: 0.9302\n",
      "Epoch 27/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1799 - accuracy: 0.9316\n",
      "Epoch 28/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1803 - accuracy: 0.9344\n",
      "Epoch 29/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1618 - accuracy: 0.9421\n",
      "Epoch 30/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1556 - accuracy: 0.9416\n",
      "Epoch 31/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1450 - accuracy: 0.9470\n",
      "Epoch 32/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1348 - accuracy: 0.9528\n",
      "Epoch 33/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1278 - accuracy: 0.9533\n",
      "Epoch 34/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1185 - accuracy: 0.9565\n",
      "Epoch 35/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1181 - accuracy: 0.9573\n",
      "Epoch 36/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1146 - accuracy: 0.9580\n",
      "Epoch 37/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1116 - accuracy: 0.9607\n",
      "Epoch 38/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1053 - accuracy: 0.9628\n",
      "Epoch 39/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.1035 - accuracy: 0.9629\n",
      "Epoch 40/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0995 - accuracy: 0.9642\n",
      "Epoch 41/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0943 - accuracy: 0.9665\n",
      "Epoch 42/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0960 - accuracy: 0.9676\n",
      "Epoch 43/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0923 - accuracy: 0.9683\n",
      "Epoch 44/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0845 - accuracy: 0.9701\n",
      "Epoch 45/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0851 - accuracy: 0.9695\n",
      "Epoch 46/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0876 - accuracy: 0.9685\n",
      "Epoch 47/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0779 - accuracy: 0.9729\n",
      "Epoch 48/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0772 - accuracy: 0.9731\n",
      "Epoch 49/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0864 - accuracy: 0.9720\n",
      "Epoch 50/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0808 - accuracy: 0.9729\n",
      "Epoch 51/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0792 - accuracy: 0.9719\n",
      "Epoch 52/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0845 - accuracy: 0.9709\n",
      "Epoch 53/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0712 - accuracy: 0.9745\n",
      "Epoch 54/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0769 - accuracy: 0.9734\n",
      "Epoch 55/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0795 - accuracy: 0.9736\n",
      "Epoch 56/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0726 - accuracy: 0.9751\n",
      "Epoch 57/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0768 - accuracy: 0.9720\n",
      "Epoch 58/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0692 - accuracy: 0.9765\n",
      "Epoch 59/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0732 - accuracy: 0.9758\n",
      "Epoch 60/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0696 - accuracy: 0.9761\n",
      "Epoch 61/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0746 - accuracy: 0.9746\n",
      "Epoch 62/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0761 - accuracy: 0.9753\n",
      "Epoch 63/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0740 - accuracy: 0.9741\n",
      "Epoch 64/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0711 - accuracy: 0.9754\n",
      "Epoch 65/2500\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0770 - accuracy: 0.9740\n",
      "Epoch 66/2500\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0660 - accuracy: 0.9783\n",
      "Epoch 67/2500\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0720 - accuracy: 0.9760\n",
      "Epoch 68/2500\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0661 - accuracy: 0.9789\n",
      "Epoch 69/2500\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0702 - accuracy: 0.9768\n",
      "Epoch 70/2500\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0728 - accuracy: 0.9751\n",
      "Epoch 71/2500\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0700 - accuracy: 0.9772\n",
      "Epoch 72/2500\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0685 - accuracy: 0.9777\n",
      "Epoch 73/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0775 - accuracy: 0.9754\n",
      "Epoch 74/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0693 - accuracy: 0.9779\n",
      "Epoch 75/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0682 - accuracy: 0.9783\n",
      "Epoch 76/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0739 - accuracy: 0.9765\n",
      "Epoch 77/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0756 - accuracy: 0.9753\n",
      "Epoch 78/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0792 - accuracy: 0.9753\n",
      "Epoch 79/2500\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.0761 - accuracy: 0.9766\n",
      "Epoch 80/2500\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0665 - accuracy: 0.9790\n",
      "Epoch 81/2500\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.0759 - accuracy: 0.9760\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00081: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, onehot, epochs=2500, batch_size=500, verbose=1,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 4)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = []\n",
    "for i in range(len(predict)):\n",
    "    submission.append(np.where(predict[i] == np.amax(predict[i]))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_y,submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def kaggleize(predictions,file):\n",
    "\n",
    "\tif(len(predictions.shape)==1):\n",
    "\t\tpredictions.shape = [predictions.shape[0],1]\n",
    "\n",
    "\tids = 1 + np.arange(predictions.shape[0])[None].T\n",
    "\tkaggle_predictions = np.hstack((ids,predictions)).astype(int)\n",
    "\twriter = csv.writer(open(file, 'w'))\n",
    "\twriter.writerow(['# id','Prediction'])\n",
    "\twriter.writerows(kaggle_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x.reshape(len(test_x), 32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = []\n",
    "for i in range(len(predict)):\n",
    "    submission.append(np.where(predict[i] == np.amax(predict[i]))[0][0])\n",
    "submission = np.array(submission)\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggleize(submission,'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNN.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
